{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "import math\n",
    "import librosa\n",
    "import os\n",
    "\n",
    "\n",
    "# good starting point but will use svc score instead\n",
    "def accuracy_estimate(genres, y_test):\n",
    "    # quick estimate\n",
    "    # lower is better\n",
    "    m = y_test.shape[0]\n",
    "    cost = sum((genres!=y_test))/m\n",
    "    return cost\n",
    "\n",
    "# does the trick but is easier to do in pandas\n",
    "# no longer using this function\n",
    "def take_m_rows_every_n(data, m, n):\n",
    "    # returns 2 1d or 2d matrices \n",
    "    # first one contains the first m out of every n datapoints (first 90 out of each 100)\n",
    "    # second one contains the remainingi n-m out of every n datapoints (last 10 out of each 100)\n",
    "    # bound to be a better way to do this... some kind of pandas mask?\n",
    "    size = data.shape[0]\n",
    "    train_size = math.ceil(size * m / n)   # if not exact division train on 1 more; test on 1 less\n",
    "    test_size = math.floor(size * (n-m) / n)\n",
    "    \n",
    "    if len(data.shape) > 1:\n",
    "        data_first = np.empty((train_size, data.shape[1])) \n",
    "        data_second = np.empty((test_size, data.shape[1]))\n",
    "    else:\n",
    "        data_first = np.empty((train_size))\n",
    "        data_second = np.empty((test_size))\n",
    "    i=0\n",
    "    j=0\n",
    "    for idx, row in enumerate(data):\n",
    "        if idx%n < m:\n",
    "            data_first[i] = row\n",
    "            i+=1\n",
    "        else:\n",
    "            data_second[j] = row\n",
    "            j+=1\n",
    "    return data_first, data_second\n",
    "\n",
    "\n",
    "# extract features from csv; code genres onto numbers\n",
    "def read_csv_extract_features(name):\n",
    "    df = pd.read_csv (name)\n",
    "    \n",
    "#     x = df.to_numpy()[:,2:-1] # all rows; don't care about the filename, length, label\n",
    "#     y_as_word = df.to_numpy()[:,-1].T  # label only\n",
    "\n",
    "    \n",
    "    classes_dict = {\n",
    "        \"blues\" : 0,\n",
    "        \"classical\" : 1,\n",
    "        \"country\" : 2,\n",
    "        \"disco\" : 3,\n",
    "        \"hiphop\" : 4,\n",
    "        \"jazz\" : 5,\n",
    "        \"metal\" : 6,\n",
    "        \"pop\" : 7,\n",
    "        \"reggae\" : 8,\n",
    "        \"rock\" : 9,\n",
    "    }\n",
    "\n",
    "#   y = np.array([classes_dict[genre] for genre in y_as_word])\n",
    "\n",
    "#   x_train, x_test = take_m_rows_every_n(x, 90, 100)\n",
    "#   y_train, y_test = take_m_rows_every_n(y, 90, 100)\n",
    "    \n",
    "    x_train = df[df.index%100 <=90].to_numpy()[:,2:-1]\n",
    "    x_test = df[df.index%100 >90].to_numpy()[:,2:-1]\n",
    "    \n",
    "    y_tr = df[df.index%100 <=90].to_numpy()[:,-1].T\n",
    "    y_tst = df[df.index%100 >90].to_numpy()[:,-1].T\n",
    "    \n",
    "    y_train = np.array([classes_dict[genre] for genre in y_tr])\n",
    "    y_test = np.array([classes_dict[genre] for genre in y_tst])\n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # I skip jazz 0054 to have the same datapoints on both 20 mel features and using the original 30 sec features\n",
    "\n",
    "    x_train, y_train, x_test, y_test = read_csv_extract_features(r'features_30_sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score linear kernel; original features; higher is better\n",
      "training score is 0.7604395604395604\n",
      "test score is 0.6333333333333333\n"
     ]
    }
   ],
   "source": [
    "    # linear kernel, from what I read appears to be somewhat optimised\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        LinearSVC(random_state=0, tol=1e-5, dual=False, C=0.01))\n",
    "    clf.fit(x_train, y_train)\n",
    "\n",
    "    score = clf.score(x_train, y_train)\n",
    "    print(\"accuracy score linear kernel; original features; higher is better\")\n",
    "    print(f\"training score is {score}\")    \n",
    "    score = clf.score(x_test, y_test)\n",
    "    print(f\"test score is {score}\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score gaussian kernel; original features; higher is better\n",
      "training score is 0.9516483516483516\n",
      "test score is 0.7777777777777778\n"
     ]
    }
   ],
   "source": [
    "    # gaussian, ovr by default\n",
    "    # gamma C optimisation seems to be beyond the scope;\n",
    "    # essentialy useless without covariance samples\n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        SVC(kernel=\"rbf\", C=1, gamma=1/30))\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    print(\"accuracy score gaussian kernel; original features; higher is better\")    \n",
    "    score = clf.score(x_train, y_train)\n",
    "    print(f\"training score is {score}\")    \n",
    "    score = clf.score(x_test, y_test)\n",
    "    print(f\"test score is {score}\")   \n",
    "    # overfitting because of my gamma choice; better than the linear kernel tho"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "    # librosa install is broken on 3.10 atm :/\n",
    "    # extract features from songs into csv\n",
    "    rootdir = 'Data\\\\genres_original\\\\'\n",
    "    csv_file = \"20melfeatures.csv\"\n",
    "    j = 0\n",
    "    lst = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            # librosa fails at jazz0054\n",
    "            try:\n",
    "                y, sr = librosa.load(subdir+\"\\\\\" +file)\n",
    "            except:\n",
    "                print(f\"failed extraction on {file}\")\n",
    "                continue\n",
    "            feat = np.mean(librosa.feature.mfcc(y=y, sr=sr), axis=1)\n",
    "            # filename; length of file, features,   label\n",
    "            row = [file, y.size] + feat.tolist() + [file.split(\".\")[0]] # make the same format as previous csv file\n",
    "            lst.append(row)\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    df.to_csv(csv_file, index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "    x_train_mel, y_train_mel, x_test_mel, y_test_mel = read_csv_extract_features(csv_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy score gaussian kernel; 20 mel features; higher is better\n",
      "training score is 0.7703296703296704\n",
      "test score is 0.5280898876404494\n"
     ]
    }
   ],
   "source": [
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        SVC(kernel=\"rbf\", C=1))\n",
    "    clf.fit(x_train_mel, y_train_mel)\n",
    "    \n",
    "    print(\"accuracy score gaussian kernel; 20 mel features; higher is better\")    \n",
    "    score = clf.score(x_train_mel, y_train_mel)\n",
    "    print(f\"training score is {score}\")    \n",
    "    score = clf.score(x_test_mel, y_test_mel)\n",
    "    print(f\"test score is {score}\")  \n",
    "    # not particularly good by themselves; \n",
    "    # makes sense because these features are a subset of the original features in the 30 sec CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
