{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "e286894c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:(1000, 57)\n",
      "y shape:(1000,)\n",
      "x train shape:(900, 57)\n",
      "y train shape:(900,)\n",
      "x test shape:(100, 57)\n",
      "y test shape:(100,)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import LinearSVC, SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "import math\n",
    "import librosa\n",
    "\n",
    "def accuracy_estimate(genres, y_test):\n",
    "    # quick estimate\n",
    "    # lower is better\n",
    "    m = y_test.shape[0]\n",
    "    cost = sum((genres!=y_test))/m\n",
    "    return cost\n",
    "\n",
    "def take_m_rows_every_n(data, m, n):\n",
    "    # returns 2 1d or 2d matrices \n",
    "    # first one contains the first m out of every n datapoints\n",
    "    # second one contains the remainingi n-m out of every n datapoints\n",
    "    # bound to be a better way to do this... some kind of pandas mask?\n",
    "    size = data.shape[0]\n",
    "    train_size = math.ceil(size * m / n)\n",
    "    test_size = math.floor(size * (n-m) / n)\n",
    "    \n",
    "    if len(data.shape) > 1:\n",
    "        data_first = np.empty((train_size, data.shape[1])) # if not exact integer will make a mess\n",
    "        data_second = np.empty((test_size, data.shape[1]))\n",
    "    else:\n",
    "        data_first = np.empty((train_size)) # if not exact integer will make a mess\n",
    "        data_second = np.empty((test_size))\n",
    "    i=0\n",
    "    j=0\n",
    "    for idx, row in enumerate(data):\n",
    "        if idx%n < m:\n",
    "            data_first[i] = row\n",
    "            i+=1\n",
    "        else:\n",
    "            data_second[j] = row\n",
    "            j+=1\n",
    "    return data_first, data_second\n",
    "\n",
    "\n",
    "\n",
    "def read_csv_extract_features(name):\n",
    "    df = pd.read_csv (name)\n",
    "    # print (df)\n",
    "\n",
    "    x = df.to_numpy()[:,2:-1] # all rows; don't care about the filename, length, label\n",
    "    # print(X)\n",
    "    print(f\"x shape:{x.shape}\")\n",
    "\n",
    "    y_as_word = df.to_numpy()[:,-1].T  # label only\n",
    "    # print(Y)\n",
    "    print(f\"y shape:{y_as_word.shape}\")\n",
    "\n",
    "    classes_dict = {\n",
    "        \"blues\" : 0,\n",
    "        \"classical\" : 1,\n",
    "        \"country\" : 2,\n",
    "        \"disco\" : 3,\n",
    "        \"hiphop\" : 4,\n",
    "        \"jazz\" : 5,\n",
    "        \"metal\" : 6,\n",
    "        \"pop\" : 7,\n",
    "        \"reggae\" : 8,\n",
    "        \"rock\" : 9,\n",
    "    }\n",
    "\n",
    "    y = np.array([classes_dict[genre] for genre in y_as_word])\n",
    "    # print(y)\n",
    "\n",
    "    x_train, x_test = take_m_rows_every_n(x, 90, 100)\n",
    "    y_train, y_test = take_m_rows_every_n(y, 90, 100)\n",
    "                                   \n",
    "    print(f\"x train shape:{x_train.shape}\")\n",
    "    print(f\"y train shape:{y_train.shape}\")   \n",
    "    print(f\"x test shape:{x_test.shape}\")\n",
    "    print(f\"y test shape:{y_test.shape}\") \n",
    "    \n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    x_train, y_train, x_test, y_test = read_csv_extract_features(r'features_30_sec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "15a691a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 1 0 0 2 2 6 5 1 1 1 1 1 1 1 1 1 1 2 2 6 2 2 2 2 2 2 0 6 3 6 6 3 6 6\n",
      " 3 3 3 3 6 4 6 8 6 4 4 4 4 5 1 5 5 5 5 5 5 5 5 5 6 0 6 6 6 6 6 6 6 7 7 7 7\n",
      " 7 7 7 7 7 7 8 8 8 2 2 7 8 5 8 6 5 6 6 9 6 2 6 6 2 6]\n",
      "0.35\n",
      "0.24\n"
     ]
    }
   ],
   "source": [
    "    # linear kernel, from what I read appears to be somewhat optimised\n",
    "    \n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        LinearSVC(random_state=0, tol=1e-5, dual=False, C=0.01))\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    results = clf.decision_function(x_test)\n",
    "    genres = results.argmax(axis=1)\n",
    "    print(genres)    \n",
    "    print(accuracy_estimate(genres, y_test))\n",
    "    \n",
    "    #overfitting..again\n",
    "    results = clf.decision_function(x_train)\n",
    "    genres = results.argmax(axis=1)\n",
    "    print(accuracy_estimate(genres, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "988a382d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 5 0 0 0 2 3 0 1 1 1 1 1 1 1 1 1 5 2 2 6 2 2 2 0 2 2 0 3 3 3 3 9 3 3\n",
      " 3 3 3 4 4 4 4 8 6 0 4 4 4 5 5 5 5 5 5 5 5 5 5 9 9 9 6 6 6 6 6 3 6 7 7 7 7\n",
      " 7 7 7 7 7 7 4 8 8 8 9 9 8 5 8 6 4 6 9 9 6 9 9 9 9 9]\n",
      "0.24\n",
      "0.05444444444444444\n"
     ]
    }
   ],
   "source": [
    "    # gaussian, ovr by default\n",
    "    # gamma C optimisation seems to be beyond the scope;\n",
    "    # essentialy useless without covariance samples\n",
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        SVC(kernel=\"rbf\", C=1, gamma=1/30))\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    results = clf.decision_function(x_test)\n",
    "    genres = results.argmax(axis=1)\n",
    "    print(genres)    \n",
    "    print(accuracy_estimate(genres, y_test))\n",
    "    \n",
    "    \n",
    "    results = clf.decision_function(x_train)\n",
    "    genres = results.argmax(axis=1)\n",
    "    print(accuracy_estimate(genres, y_train))\n",
    "    # seems to be overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "f9b8b956",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nikol\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\librosa\\core\\audio.py:165: UserWarning: PySoundFile failed. Trying audioread instead.\n",
      "  warnings.warn(\"PySoundFile failed. Trying audioread instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "failed extraction on jazz.00054.wav\n"
     ]
    }
   ],
   "source": [
    "    # librosa install is broken on 3.10 atm :/\n",
    "    rootdir = 'Data\\\\genres_original\\\\'\n",
    "\n",
    "    import os\n",
    "    j = 0\n",
    "    lst = []\n",
    "    for subdir, dirs, files in os.walk(rootdir):\n",
    "        for file in files:\n",
    "            try:\n",
    "                y, sr = librosa.load(subdir+\"\\\\\" +file)\n",
    "            except:\n",
    "                print(f\"failed extraction on {file}\")\n",
    "                continue\n",
    "            feat = np.mean(librosa.feature.mfcc(y=y, sr=sr), axis=1)\n",
    "            row = [file, y.size] + feat.tolist() + [file.split(\".\")[0]] # make the same format as previous csv file\n",
    "            lst.append(row)\n",
    "\n",
    "    df = pd.DataFrame(lst)\n",
    "    df.to_csv('20melfeatures.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "82ab8513",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape:(999, 20)\n",
      "y shape:(999,)\n",
      "x train shape:(900, 20)\n",
      "y train shape:(900,)\n",
      "x test shape:(99, 20)\n",
      "y test shape:(99,)\n"
     ]
    }
   ],
   "source": [
    "    x_train, y_train, x_test, y_test = read_csv_extract_features(r'20melfeatures.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b251bac9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 2 0 0 2 9 2 0 6 2 5 8 1 1 1 1 1 5 1 5 2 2 6 2 0 0 2 0 2 9 4 9 4 3 3 4 4\n",
      " 3 9 9 4 4 4 6 4 6 9 3 4 9 8 5 5 5 5 5 5 8 5 4 9 9 6 6 6 6 6 6 6 7 7 7 7 7\n",
      " 7 7 7 7 7 3 8 8 7 2 2 8 2 8 4 9 6 9 9 6 9 9 6 2 0]\n",
      "0.43434343434343436\n",
      "0.23777777777777778\n"
     ]
    }
   ],
   "source": [
    "    clf = make_pipeline(StandardScaler(),\n",
    "                        SVC(kernel=\"rbf\", C=1))\n",
    "    clf.fit(x_train, y_train)\n",
    "    \n",
    "    results = clf.decision_function(x_test)\n",
    "    genres = results.argmax(axis=1)\n",
    "    print(genres)\n",
    "    print(accuracy_estimate(genres, y_test))\n",
    "    \n",
    "        \n",
    "    results = clf.decision_function(x_train)\n",
    "    genres = results.argmax(axis=1)\n",
    "    print(accuracy_estimate(genres, y_train))\n",
    "    # again overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4ef1209",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
